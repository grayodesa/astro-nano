---
date: "2025-04-14T13:00:50"
draft: false
url: /5811
source: "https://www.bleepingcomputer.com/news/security/ai-hallucinated-code-dependencies-become-new-supply-chain-risk/"
---

Исследователи выявили новый класс атак на цепочку поставок под названием "slopsquatting", связанный с использованием генеративного ИИ для написания кода. Проблема возникает из-за склонности AI-моделей "галлюцинировать" несуществующие имена пакетов.

В отличие от традиционного typosquatting, где злоумышленники используют опечатки в названиях популярных библиотек, slopsquatting основан на создании вредоносных пакетов с названиями, которые AI регулярно придумывает в своих кодовых примерах.

Недавнее исследование показало, что примерно в 20% случаев (из 576 000 проанализированных примеров кода на Python и JavaScript) рекомендованные ИИ пакеты на самом деле не существуют. Проблема особенно заметна в открытых моделях типа CodeLlama и DeepSeek, но даже коммерческие инструменты вроде GPT-4 ошибаются примерно в 5% случаев.

58% "галлюцинированных" имен пакетов повторялись более одного раза в десяти запусках, что делает их предсказуемыми целями для атак. При этом 38% названий были вдохновлены реальными пакетами, 13% были результатом опечаток, а 51% — полностью выдуманными.

Хотя пока нет признаков активного использования этой уязвимости злоумышленниками, исследователи из компании Socket предупреждают, что семантически правдоподобные и повторяющиеся имена пакетов создают предсказуемые возможности для атак.

Для защиты рекомендуется всегда вручную проверять имена пакетов, использовать сканеры зависимостей, файлы блокировки и верификацию хешей. Также помогает снижение параметра "температуры" в настройках AI и тестирование сгенерированного кода в изолированной среде перед его использованием в продакшене.