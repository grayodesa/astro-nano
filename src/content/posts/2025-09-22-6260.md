---
date: "2025-09-22T16:50:52"
draft: false
url: "/6260"
source: "https://deepmind.google/discover/blog/strengthening-our-frontier-safety-framework/"
images:
    -
forwarded_from: ""
---

Google DeepMind публикует третью итерацию Frontier Safety Framework — самую детализированную версию системы оценки рисков от продвинутых AI-моделей. Главное нововведение — Critical Capability Level для harmful manipulation, когда модель может систематически менять убеждения и поведение людей в критически важных контекстах.

Компания фактически признает возможность потери контроля над моделями. В документе прямо говорится о сценариях, где "неправильно настроенные модели искусственного интеллекта могут помешать операторам управлять, изменять или прекращать свои операции". Раньше это обсуждалось как нечто гипотетическое — теперь же в документе разработаны конкретные протоколы для моделей, которые способны развиться до потенциально небезопасного уровня.

Фреймворк описывает и протоколы тестирования новых моделей — причем не только перед обнародованием моделей на публику, но и масштабных внутренних развертываниях. То есть признается возможность проблем с моделями и при их тестовой эксплуатации внутри компании.

В общем, к деплою Skynet готовы.
