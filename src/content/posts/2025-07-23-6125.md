---
date: "2025-07-23T13:42:48"
draft: false
url: "/6125"
source: "https://qwenlm.github.io/blog/qwen3-coder/"
images:
    -
forwarded_from: ""
---

Qwen представил Qwen3-Coder — модель с 480 миллиардами параметров для программирования, которая показывает результаты, сопоставимые с Claude Sonnet 4 на задачах генерации кода и работы с инструментами. Модель поддерживает контекст до 256 тысяч токенов нативно и до миллиона с методами экстраполяции.

Довольно любопытно, что для обучения использовали 7,5 триллиона токенов с 70-процентным содержанием кода. Это заметно больше, чем у большинства конкурентов. Еще интереснее подход к очистке данных — разработчики использовали предыдущую версию Qwen2.5-Coder для переписывания "шумных" участков кода в обучающей выборке. 

Команда разработчиков решила не заниматься построением экосистемы с нуля, а сделала форк Gemini Code под названием Qwen Code, и обеспечила совместимость с Claude Code.

Тут у меня, как у потребителя, возникают сложные ощущения — с одной стороны, попробовать хочется всё, с другой — менять рабочий инструмент, которым является Claude Code, не очень хочется. 

Но попробовать можно — на chat.qwen.ai хоть сейчас.
