---
date: "2025-09-14T00:11:33"
draft: false
url: "/6246"
source: "https://techcrunch.com/2025/09/10/thinking-machines-lab-wants-to-make-ai-models-more-consistent/"
images:
    -
forwarded_from: ""
---

Мира Мурати наконец показала, над чем работает её Thinking Machines Lab с двумя миллиардами seed-финансирования. На этой неделе компания запустила собственный блог и выложила первую статью в нем. Статья посвящена попытке сделать ответы LLM детерминированными — воспроизводимыми при одинаковых запросах.

Исследователь Хорас Хе пишет о проблеме недетерминированности в LLM — когда даже при установке температуры в 0, API языковых моделей выдают разные результаты при одинаковых запросах. Многие считают, что причина недетерминированности - это комбинация параллельных вычислений и неассоциативности операций с плавающей точкой на GPU. Хорас показывает, что это не полная картина.

Главная причина недетерминированности - отсутствие batch-инвариантности в ядрах GPU. Когда размер батча (количество одновременно обрабатываемых запросов) меняется, результаты для отдельных элементов могут отличаться из-за разного порядка суммирования чисел с плавающей точкой. В статье предлагается создать batch-инвариантные версии ключевых операций. По результатам тестирования на модели Qwen3-235B удалось добиться полной идентичности ответов — правда, ценой снижения производительности в 1,6 раза. 

Это, конечно, еще не полное оправдания полученного финансирования, но хорошая иллюстрация его полезности, как мне кажется.
