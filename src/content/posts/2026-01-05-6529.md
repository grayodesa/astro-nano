---
date: "2026-01-05T10:29:17"
draft: false
url: "/6529"
source: "https://github.com/alexzhang13/rlm"
images: []
forwarded_from: ""
---

Готовы возвращаться после праздников? Аккурат 31 декабря несколько исследователей из MIT представили Recursive Language Models — парадигму, при которой языковая модель может рекурсивно вызывать саму себя, декомпозируя задачу и работая с контекстом как с переменной в интерактивной среде. Мне статья и этот репозиторий уже попался в твиттере раз десять, так что имеет смысл посмотреть.

По сути, это попытка обойти ограничения контекстного окна не расширением памяти или разными способами фиксации сессий, а делегированием модели права самой управлять своим вниманием. Практически это выглядит как своеобразный агент, который работает с переменной context длинной до 10М+ токенов (по крайней мере, на таком объеме тестировали), пишет код для нахождения нужной информации в контексте, вызывает сама себя для изучения полученной информации. Чем-то это напоминает классический RAG, но в данном случае модель сама управляет процессом поиска по данным, определяя стратегию решения задачи.

Конечно, минусом является то, что всё это требует намного больших ресурсов — вместо одного вызова API LLM делается много вызовов, кроме того, сам подход к решению задачи с написанием кода и обработкой его результатов исключает быстрые ответы. Но вот для задач типа Deep Research это может оказаться полезным подходом.

Пока результаты неплохие — по всем бенчмаркам результаты в разы выше оригинальных моделей (использовались GPT-5 и Qwen3-Coder), причем оригинальные модели часто не справлялись с задачей полностью из-за ограничений контекста.