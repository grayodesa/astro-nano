---
date: "2025-01-20T16:20:28"
draft: false
url: "/5571"
source: "https://github.com/deepseek-ai/DeepSeek-R1"

---

DeepSeek представила новые модели для рассуждений — DeepSeek-R1-Zero и DeepSeek-R1, а также серию их дистиллированных версий. Интересно, что R1-Zero обучалась только через reinforcement learning без предварительной supervised fine-tuning, что является первым подобным успешным экспериментом в открытом доступе.

DeepSeek-R1, получившая дополнительное обучение на специально подготовленных данных, показывает результаты на уровне OpenAI o1 в задачах математики, программирования и рассуждений. Компания также выпустила шесть уменьшенных моделей на базе Llama и Qwen — от 1.5B до 70B параметров.

Особенно впечатляет DeepSeek-R1-Distill-Qwen-32B, которая превосходит OpenAI o1-mini по многим показателям. На математических тестах AIME 2024 она показывает результат 72.6% против 63.6% у o1-mini, а на MATH-500 — 94.3% против 90%.

Все модели доступны в открытом доступе под лицензией MIT и поддерживают коммерческое использование. Правда, основную модель — R1, — вы все равно локально не запустите с её 671B параметров. Но попробовать можно на [chat.deepseek.com](chat.deepseek.com). По паре вопросов сориентироваться сложно, но отвечает похоже на o1, причем за считанные секунды, в отличие от. При этом даже слегка удивительно, что модель отвечает, не прибегая к иероглифам, как другие китайские модели. В общем, попробуйте, конкуренция явно накаляется.
