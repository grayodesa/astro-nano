---
date: "2025-02-06T16:04:49"
draft: false
url: /5627
source: "https://satori-reasoning.github.io/blog/satori/"
---

Вот вам еще одна разработка исследователей — на этот раз из MIT и Гарварда, — на тему обучения моделей рассуждениям. В этом случае исследователи, чтобы обойтись без дорогостоящего обучения с участием большой модели, применением RLHF и SFT, разработали метод "Chain-of-Action-Thought" (COAT), когда сначала для модели генерируется небольшой обучающий набор рассуждений, а затем модель по нему обучается в процессе генерации промежуточных звеньев в цепочке останавливаться, оценивать решение, искать альтернативный подход и двигаться дальше. 

Ключевая особенность подхода Satori в том, что модель учится рассуждать без внешнего руководства, она сама оценивает промежуточные результаты и сама ищет альтернативные решения. При этом навыки рассуждения, полученные на математических задачах, успешно переносятся на другие области — логику, программирование и так далее. 

Обученная на базе Qwen-7B модель обошла по тестам своих одноклассников и даже большие (Llama 70B) модели, а в других областях продемонстрировала результаты на уровне лидеров, при том, что она не обучалась на материале этих тем.

Но еще одну ссылку я дам [на свой блог](https://blognot.co/prodolzhaem-pisat-vmeste-s-ai/) — поскольку обсуждая статью с LLM, у нас родилась идея, что аналогичный подход можно реализовать с помощью few shot на топовой LLM и оказалось, что действительно можно и результаты получаются заметно лучше, чем даже с традиционными примерами "вопрос-ответ". Правда, промпт получается немаленький, но… читайте в блоге, я там описал подробности.