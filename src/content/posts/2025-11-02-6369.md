---
date: "2025-11-02T11:10:14"
draft: false
url: "/6369"
source: "https://www.anthropic.com/research/introspection"
images: []
forwarded_from: ""
---

Anthropic опубликовала исследование о способности LLM к интроспекции — возможности модели анализировать собственные внутренние состояния. Методика любопытная: они записывали паттерны нейронной активности модели при обработке определенных концептов (например, текста заглавными буквами), а затем искусственно вводили эти паттерны в несвязанном контексте. Claude Opus 4.1 в 20% случаев обнаруживала инъекцию и корректно идентифицировала концепт.

Ключевое отличие от предыдущих экспериментов с активационным стирингом — модель сообщает об обнаружении аномалии до того, как начинает говорить о самом концепте. В случае с "Golden Gate Claude" модель осознавала свою одержимость мостом только постфактум, видя собственные ответы. Здесь распознавание происходит на внутреннем уровне обработки.

Неожиданная деталь — "helpful-only" версии моделей показывали лучшие результаты интроспекции, чем продакшн-варианты. Это указывает, что процесс файн-тюнинга для безопасности может подавлять эти способности. Anthropic также обнаружила, что модели реагируют на инсентивы ("если подумаешь о X, получишь награду") так же, как на прямые инструкции — возможно, это общая система управления вниманием.

Конечно, 20% — это совсем мало и ненадежно, но, как принято говорить, мы в самом начале пути. Если вам интересно, к чему, то уточню, что интроспекция считается важной (хотя и недостаточной) чертой собственного сознания. По крайней мере, у людей это так.