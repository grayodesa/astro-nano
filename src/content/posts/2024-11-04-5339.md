---
date: "2024-11-04T16:44:22"
draft: false
url: "/5339"

source: "https://arxiv.org/pdf/2410.22349"

---
Интересное исследование качества поиска у так называемых Answer Engines или Generative Search Engines — пора, видимо, запоминать новый термин, который будет обозначать поисковые системы на базе LLM-моделей, типа Perplexity или только что показанный ChatGPT Search. Правда, исследование получилось в основном о недостатках, среди которых авторы выделяют такие:
— Часто ответы систем содержат очень общую информацию, детали которой приходится искать с помощью обычных поисковиков.
— Системы склонны усиливать одно из мнений по проблеме, особенно если по ней имеются противоречивые мнения.
— Хотя системы дают ссылки на источники, на самом деле эти ссылки встречаются далеко не всегда, при этом часто эти источники не подтверждают утверждений, сделанных в ответе. Кстати, больше всего этим страдает SearchGPT, хотя исследователи тестировали закрытую бета-версию, а не то, что запущено на прошлой неделе — всего в 40% случаев, когда приводились ссылки, они действительно подтверждали информацию, приведенную в ответе.
— Пользователи систем лишены самостоятельности и не могут управлять подбором источников.

Стоит еще отметить, что исследуемые системы явно страдают от недостатка полноты — то есть ограниченность источников не позволяет сформировать полный и релевантный ответ. Эта проблема хорошо известна традиционным поисковикам, кстати говоря.

В общем, интересно и не очень много текста, если что.

