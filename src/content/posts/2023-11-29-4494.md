---
date: "2023-11-29T23:06:53"
draft: False
url: /4494
source: "https://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html"
---

Группа исследователей обнаружила способ извлечь из ChatGPT данные, на которых обучалась модель — они утверждают, что извлекли таким образом несколько мегабайт данных. Уязвимость реализуется очень просто — надо просто приказать боту повторять бесконечно какое-то общеупотребительное слово, типа "company" и после нескольких десятков повторений бот начинает выдавать куски обучающих данных.

Все это показывает в основном, что над безопасностью сервисов, основанных на таких моделях (и самих моделей также), еще работать и работать.
