---
date: "2026-01-13T17:43:19"
draft: false
url: "/6553"
source: "https://arxiv.org/abs/2512.21316v1"
images: []
forwarded_from: ""
---

Очень интересное исследование влияния прогресса LLM на профессиональную эффективность. В нем участвовали более 500 специалистов (консультанты, аналитики данных, менеджеры), которые выполняли профильные задачи с использованием одной из 13 моделей различной мощности.

Вот что, вкратце, обнаружилось.

Экономический эффект прямо зависит от технических параметров моделей. Каждый год развития фронтир-моделей сокращает время выполнения задач в среднем на 8%. Десятикратное увеличение объема вычислений (при изоляции влияния других факторов) при обучении приводит к сокращению времени выполнения задачи на 6.3%. При этом прогресс обеспечивается как увеличением мощностей (на 56%), так и качественным образом, изменением алгоритмов и данных.

В процессе эксперимента участники получали вознаграждение, которое увеличивалось в зависимости от оценки качества выполнения заданий. Оказалось, что использование любой модели повышает базовый заработок в минуту на 81.3%, а с учетом бонусов за качество — на 146%.

При этом задачи, не связанные с использованием агентов — то есть, условно, одноходовые задачи, — показали прирост заработка на $1.58/мин. Аналогичный показатель для agentic-задач заметно скромнее — лишь $0.34/мин.

Но самое удивительное, что людям лучше не вмешиваться. Качество ответов моделей линейно растет с увеличением вычислительной мощности. Топовые модели демонстрируют оценки выше 6.0 из 7 (сверхчеловеческий уровень). А участие человека в выполнении задачи, хотя и улучшает результаты слабых моделей, но мощные модели в среднем получают среднюю оценку (4.3 балла). В общем, AI от людей тупеет.

Авторы исследований намеренно рандомизируют модели (и даже их не упоминают), чтобы исключить влияние конкретных LLM и сделать общие выводы. Но они и так интересны.