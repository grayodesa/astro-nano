---
date: "2025-08-05T21:36:35"
draft: false
url: "/6167"
source: "https://openai.com/index/introducing-gpt-oss/"
images:
    -
forwarded_from: ""
---

Мы ждали и дождались — OpenAI выпускает целых две open-weight модели — gpt-oss-120b и gpt-oss-20b под лицензией Apache 2.0.

Технически это mixture-of-experts модели, где активируется лишь малая часть параметров. У 120-миллиардной версии работает только 5.1B на токен, что позволяет запускать её на одной 80GB GPU. Младшая 20-миллиардная модель вообще помещается в 16GB памяти.

По производительности модели приближаются к проприетарным аналогам OpenAI — o4-mini и o3-mini соответственно, а на некоторых обе модели обходят o1 и GPT-4o.

OpenAI намеренно попыталась "сломать" собственные модели, дообучив их на опасных данных по биологии и кибербезопасности. Затем протестировала, насколько опасными они могут стать. Вывод: даже после агрессивного fine-tuning модели не достигают критического уровня capabilities по их Preparedness Framework. Методологию проверяли три независимые группы экспертов.

Это заодно объясняет, чем занимались разработчики примерно последний месяц, пока Сэм Альтман объяснял, почему модель задерживается.

Chain-of-thought специально оставили без supervision — чтобы можно было отслеживать потенциально вредное поведение модели. Правда, это означает, что в рассуждениях могут быть галлюцинации и небезопасный контент.

Вообще, это интересно не только с точки зрения использования моделей on-premise, что важно для компаний, но и с точки зрения возможного fine-tune — на данный момент последняя модель, которую можно дообучить, это GPT-4o, если новые модели лучше, это уже прогресс.
