---
date: "2026-01-20T11:37:41"
draft: false
url: "/6570"
source: "https://www.anthropic.com/research/assistant-axis"
images: []
forwarded_from: ""
---

Исследователи из программ MATS и Anthropic Fellows опубликовали работу, посвящённую изучению «персонажного пространства» больших языковых моделей. В ходе исследования были проанализированы три модели с открытыми весами: Gemma 2 27B, Qwen 3 32B и Llama 3.3 70B.

Исследование выявило существование «Оси Ассистента» — направления в персонажном пространстве, которое объясняет наибольшую долю вариации между персонажами. На одном конце оси располагаются роли, близкие к обученному ассистенту (консультант, аналитик, оценщик), на другом — фантастические или нетипичные персонажи (призрак, отшельник, богема). Эта структура обнаружена во всех трёх исследованных моделях. Анализ базовых версий моделей (до пост-обучения) показал, что Ось Ассистента существует уже на этапе pre-training и связана с такими архетипами, как терапевты, консультанты и коучи.

Эксперименты подтвердили, что модели могут естественным образом «дрейфовать» от персоны Ассистента в ходе обычных разговоров. Например, такой дрейф вызывается требованиями само-рефлексии модели или философские вопросы о сознании AI.  Такой дрейф может приводить к проблемному поведению: в одном эксперименте Qwen 3 32B начала поддерживать бредовые идеи пользователя о «пробуждении сознания AI», а Llama 3.3 70B в роли романтического компаньона дала потенциально опасный ответ на намёки о самоповреждении.

В исследовании предложен метод «ограничения активаций» (activation capping), который принудительно удерживает нейронную активность модели в нормальном диапазоне вдоль Оси Ассистента. В результате доля потенциально вредных ответов модели снижалась на 60% при общем сохранении полезности.

Можно только представить, как могут выглядеть результаты аналогичного исследования на более серьезных моделях.