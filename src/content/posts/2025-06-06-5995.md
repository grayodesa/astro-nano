---
date: "2025-06-06T14:34:38"
draft: false
url: "/5995"
source: "https://www.washingtonpost.com/technology/2025/06/04/ai-summarizers-analysis-test-documents-books/?ref=platformer.news"
images:
    -
forwarded_from: ""
---

Журналист Washington Post провел масштабное тестирование пяти популярных AI-чатботов (ChatGPT, Claude, Copilot, Meta AI и Gemini) на способность понимать и анализировать различные типы текстов — от художественной литературы до юридических документов и политических речей Трампа.

Результаты оказались неоднозначными. Победитель Claude набрал в среднем 67% правильных ответов, ChatGPT — 64%. Остальные значительно отстали. При этом Claude был единственным, кто не "галлюцинировал" — не выдумывал несуществующие факты.

Интересно, что успех в одной области не гарантировал успеха в другой. ChatGPT лучше всех справился с анализом литературы и политических речей, но провалился на юридических документах. Claude показал стабильность во всех категориях.

AI часто пропускает важную информацию, акцентирует позитивное и игнорирует негативное, может давать поверхностные ответы вместо глубокого анализа. Например, при анализе романа о Гражданской войне в США боты часто обходили стороной темы рабства.

Впрочем, я думаю, что у любого, кто активно использует AI, в запасе есть с десяток историй, как галлюцинирует кто угодно. Мне буквально пять минут назад Claude объяснял, что 8 утра в Киеве — это 11:00 UTC и он нашел баг.
